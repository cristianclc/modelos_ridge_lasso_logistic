

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Modelos Ridge, Lasso y LogisticRegression &#8212; cl_jbook_ml202530</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'miniproject';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Información del Dataset" href="intromini.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intromini.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/uninorte.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/uninorte.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intromini.html">
                    Información del Dataset
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Modelos Ridge, Lasso y LogisticRegression</a></li>




</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fminiproject.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/miniproject.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Modelos Ridge, Lasso y LogisticRegression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Modelos Ridge, Lasso y LogisticRegression</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#importar-librerias">Importar Librerías</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#lectura-de-datos">Lectura de Datos</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tratamiento-de-outliers-en-variables-numericas">Tratamiento de outliers en variables numéricas</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#price">Price</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#odometer">Odometer</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#valores-nulos">Valores Nulos</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocesamiento">Preprocesamiento</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminacion-de-variables">Eliminación de Variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminacion-de-observaciones-con-valores-faltantes-na">Eliminación de Observaciones con Valores Faltantes (NA)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#valores-unicos">Valores únicos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creacion-de-la-variable-binaria-highdemand">Creación de la Variable Binaria “HighDemand”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#separacion-de-los-conjutos-x-y-reg-y-clf">Separación de los conjutos X, y_reg, y_clf</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-correlacion-no-parametrica-para-variables-numericas-spearman">Análisis de Correlación No Paramétrica para Variables Numéricas (Spearman)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#agrupamiento-de-variables-categoricas-de-alta-cardinalidad">Agrupamiento de Variables Categóricas de Alta Cardinalidad</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preservacion-selectiva-de-modelos-por-frecuencia">Preservación Selectiva de Modelos por Frecuencia</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-relevancia-de-variables-categoricas-prueba-de-kruskal-wallis">Análisis de Relevancia de Variables Categóricas (Prueba de Kruskal-Wallis)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#seleccion-de-variables-basada-en-relevancia-predictiva-y-manejo-de-categoricas">Selección de Variables Basada en Relevancia Predictiva y Manejo de Categoricas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuracion-de-la-busqueda-de-hiperparametros-con-gridsearchcv">Configuración de la Búsqueda de Hiperparámetros con GridSearchCV</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepocesamiento-variables-categoricas-y-numericas">Prepocesamiento variables categóricas y numéricas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creacion-de-conjuntos-de-entrenamiento-y-prueba">Creación de Conjuntos de Entrenamiento y Prueba</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejecucion-de-la-busqueda-de-hiperparametros-y-entrenamiento-de-los-modelos">Ejecución de la Búsqueda de Hiperparámetros y Entrenamiento de los Modelos</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge">Ridge</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">Lasso</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-logistica">Regresión Logística</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-los-resultados-de-la-busqueda-de-hiperparametros">Análisis de los Resultados de la Búsqueda de Hiperparámetros</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion-de-desempeno">Evaluación de desempeño</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Ridge</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Lasso</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion-final-del-modelo-de-clasificacion-en-el-conjunto-de-prueba">Evaluación Final del Modelo de Clasificación en el Conjunto de Prueba</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Regresión logística</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="modelos-ridge-lasso-y-logisticregression">
<h1>Modelos Ridge, Lasso y LogisticRegression<a class="headerlink" href="#modelos-ridge-lasso-y-logisticregression" title="Permalink to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="importar-librerias">
<h1>Importar Librerías<a class="headerlink" href="#importar-librerias" title="Permalink to this heading">#</a></h1>
<p>Se importan las librerías esenciales para facilitar el análisis que abarca la carga de datos, la evaluación estadística, la visualización, la transformación de datos, la fusión y la unión.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#pip install kagglehub</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">kagglehub</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">kruskal</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">spearmanr</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\USER\miniconda3\envs\ml_venv\lib\site-packages\tqdm\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="lectura-de-datos">
<h1>Lectura de Datos<a class="headerlink" href="#lectura-de-datos" title="Permalink to this heading">#</a></h1>
<p>Para la carga inicial del dataset, se utilizó la API de Kaggle Hub mediante Python, permitiendo una descarga automatizada y eficiente de los datos más recientes. El proceso consistió en:</p>
<ol class="arabic simple">
<li><p><strong>Descarga del Dataset</strong>: Se obtuvo la versión actualizada del dataset ‘Craigslist CarsTrucks Data’ directamente desde Kaggle, almacenándose localmente en una ruta específica del sistema.</p></li>
<li><p><strong>Verificación de Archivos</strong>: Se listaron los archivos descargados para confirmar la presencia del archivo principal (<code class="docutils literal notranslate"><span class="pre">vehicles.csv</span></code>).</p></li>
<li><p><strong>Carga en DataFrame</strong>: El archivo CSV se leyó utilizando Pandas, asegurando una estructura lista para el análisis posterior.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">kagglehub</span><span class="o">.</span><span class="n">dataset_download</span><span class="p">(</span><span class="s2">&quot;austinreese/craigslist-carstrucks-data&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Path to dataset files:&quot;</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Path to dataset files: C:\Users\USER\.cache\kagglehub\datasets\austinreese\craigslist-carstrucks-data\versions\10
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">downloaded_files</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Archivos disponibles:&quot;</span><span class="p">,</span> <span class="n">downloaded_files</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Archivos disponibles: [&#39;vehicles.csv&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">csv_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;vehicles.csv&quot;</span><span class="p">)</span> 

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p>Se emplea el método <code class="docutils literal notranslate"><span class="pre">df.info()</span></code> para evaluar la estructura y calidad inicial del dataset. Este análisis revela información sobre la composición de los datos, incluyendo el número total de registros (filas) y variables (columnas), los tipos de datos asociados a cada campo (como objetos, enteros o valores flotantes), y la cantidad de valores no nulos por columna.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 426880 entries, 0 to 426879
Data columns (total 26 columns):
 #   Column        Non-Null Count   Dtype  
---  ------        --------------   -----  
 0   id            426880 non-null  int64  
 1   url           426880 non-null  object 
 2   region        426880 non-null  object 
 3   region_url    426880 non-null  object 
 4   price         426880 non-null  int64  
 5   year          425675 non-null  float64
 6   manufacturer  409234 non-null  object 
 7   model         421603 non-null  object 
 8   condition     252776 non-null  object 
 9   cylinders     249202 non-null  object 
 10  fuel          423867 non-null  object 
 11  odometer      422480 non-null  float64
 12  title_status  418638 non-null  object 
 13  transmission  424324 non-null  object 
 14  VIN           265838 non-null  object 
 15  drive         296313 non-null  object 
 16  size          120519 non-null  object 
 17  type          334022 non-null  object 
 18  paint_color   296677 non-null  object 
 19  image_url     426812 non-null  object 
 20  description   426810 non-null  object 
 21  county        0 non-null       float64
 22  state         426880 non-null  object 
 23  lat           420331 non-null  float64
 24  long          420331 non-null  float64
 25  posting_date  426812 non-null  object 
dtypes: float64(5), int64(2), object(19)
memory usage: 84.7+ MB
</pre></div>
</div>
</div>
</div>
<p><strong>Interpretación del Dataset</strong></p>
<ol class="arabic simple">
<li><p><strong>Volumen y Dimensiones</strong>:</p>
<ul class="simple">
<li><p>El conjunto de datos contiene 426,880 registros (filas) y 26 variables (columnas), lo que representa un volumen considerable de información sobre vehículos.</p></li>
</ul>
</li>
<li><p><strong>Tipos de Datos</strong>:</p>
<ul class="simple">
<li><p>Predominan variables categóricas/cualitativas (19 columnas tipo object).</p></li>
<li><p>Variables numéricas incluyen 4 columnas float64 (<code class="docutils literal notranslate"><span class="pre">year</span></code>, <code class="docutils literal notranslate"><span class="pre">odometer</span></code>, <code class="docutils literal notranslate"><span class="pre">lat</span></code>, <code class="docutils literal notranslate"><span class="pre">long</span></code>) y 2 int64 (<code class="docutils literal notranslate"><span class="pre">id</span></code> y <code class="docutils literal notranslate"><span class="pre">price</span></code>). La variable <code class="docutils literal notranslate"><span class="pre">county</span></code> es tomada como float64 pero la columna esta totalmente vacía.</p></li>
<li><p>La columna <code class="docutils literal notranslate"><span class="pre">posting_date</span></code> está como texto (object), requiriendo conversión a datetime.</p></li>
</ul>
</li>
</ol>
<p>El dataset presenta un volumen masivo (426,880 registros) con amplia dimensionalidad (26 variables), ofreciendo un amplio potencial para análisis multivariados. Sin embargo, existe un desequilibrio significativo en la composición de datos, con predominio de variables categóricas (19 columnas) sobre numéricas (7 columnas), lo que implica desafíos en el preprocesamiento para modelos predictivos. La combinación de tamaño sustancial y diversidad de variables proporciona una base sólida para análisis exhaustivos, aunque requiere transformaciones intensivas en el manejo de fechas y limpieza de columnas vacías para maximizar su utilidad analítica.</p>
<section id="tratamiento-de-outliers-en-variables-numericas">
<h2>Tratamiento de outliers en variables numéricas<a class="headerlink" href="#tratamiento-de-outliers-en-variables-numericas" title="Permalink to this heading">#</a></h2>
<p>Con el objetivo de mitigar la influencia de valores atípicos extremos en las variables numéricas odometer y year, se aplicará un procedimiento de limpieza basado en percentiles. En particular, se eliminarán aquellas observaciones cuyos valores superen el percentil 99 de cada variable, ya que estos pueden distorsionar los análisis estadísticos posteriores o afectar negativamente el desempeño de los modelos predictivos. Este enfoque permite conservar la mayor parte de la información útil del conjunto de datos, al tiempo que se controla el efecto de outliers que podrían no ser representativos del comportamiento general del mercado.</p>
<section id="price">
<h3>Price<a class="headerlink" href="#price" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s2">,.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count          426,880.00
mean            75,199.03
std         12,182,282.17
min                  0.00
25%              5,900.00
50%             13,950.00
75%             26,485.75
max      3,736,928,711.00
Name: price, dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Boxplot de Price&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Precio&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/96e6137b88d931498cc6c5b76b69f362652c6072950cb1d7a82b1c3c74d5d64f.png" src="_images/96e6137b88d931498cc6c5b76b69f362652c6072950cb1d7a82b1c3c74d5d64f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">upper_bound</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.99</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Límites: </span><span class="si">{</span><span class="n">upper_bound</span><span class="si">:</span><span class="s2">,.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">upper_bound</span><span class="p">)]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Límites: 66,995.00
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s2">,.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count    422,615.00
mean      16,762.50
std       13,791.40
min            0.00
25%        5,899.00
50%       13,680.00
75%       25,990.00
max       66,995.00
Name: price, dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Boxplot de Price&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Precio&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a65588d819298760f6dd5cc15b47896bba9bbb602b098e3e5b914303c0d87608.png" src="_images/a65588d819298760f6dd5cc15b47896bba9bbb602b098e3e5b914303c0d87608.png" />
</div>
</div>
</section>
<section id="odometer">
<h3>Odometer<a class="headerlink" href="#odometer" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;odometer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s2">,.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count       418,261.00
mean         98,645.47
std         214,128.34
min               0.00
25%          38,670.00
50%          86,432.00
75%         134,000.00
max      10,000,000.00
Name: odometer, dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">upper_bound</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;odometer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.99</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Límites: </span><span class="si">{</span><span class="n">upper_bound</span><span class="si">:</span><span class="s2">,.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;odometer&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">upper_bound</span><span class="p">)]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Registros después de eliminar outliers: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Límites: 279,984.40
Registros después de eliminar outliers: 414078
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;odometer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s2">,.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count    414,078.00
mean      90,252.85
std       60,408.38
min            0.00
25%       38,130.00
50%       85,391.50
75%      132,172.00
max      279,974.00
Name: odometer, dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;odometer&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Boxplot de odometer&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;odometer&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a591b7daf34323ca30939880eb1e831e1b1de747edd27e4da3d80157b2eca8e2.png" src="_images/a591b7daf34323ca30939880eb1e831e1b1de747edd27e4da3d80157b2eca8e2.png" />
</div>
</div>
</section>
</section>
<section id="valores-nulos">
<h2>Valores Nulos<a class="headerlink" href="#valores-nulos" title="Permalink to this heading">#</a></h2>
<p>Para cuantificar la magnitud de datos ausentes en cada columna, se calculó el porcentaje de valores nulos mediante <code class="docutils literal notranslate"><span class="pre">df.isnull().mean()</span> <span class="pre">*</span> <span class="pre">100</span></code>. Este indicador permite identificar variables críticas que requieren intervención prioritaria en el proceso de limpieza. Además, trabajaremos los valores de 0 en la variable precio como valores faltantes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>id                0.000000
url               0.000000
region            0.000000
region_url        0.000000
price             7.377113
year              0.246330
manufacturer      3.854105
model             1.161858
condition        40.390699
cylinders        41.309608
fuel              0.565111
odometer          0.000000
title_status      1.807630
transmission      0.396302
VIN              37.409618
drive            30.534827
size             71.649303
type             21.551978
paint_color      30.249615
image_url         0.000000
description       0.000483
county          100.000000
state             0.000000
lat               1.557436
long              1.557436
posting_date      0.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<p><strong>Interpretación de Valores Nulos</strong></p>
<ol class="arabic simple">
<li><p><strong>Variables Completas (0% faltantes)</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">id</span></code> y <code class="docutils literal notranslate"><span class="pre">url</span></code> (0%): Son identificadores únicos del sistema. Su completitud del 100% indica que la base de datos mantiene integridad en su estructura fundamental. Esto es crítico para trazar cada registro individualmente.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">region</span></code> y <code class="docutils literal notranslate"><span class="pre">region_url</span></code> (0%): La ubicación geográfica principal está siempre registrada. Esto sugiere que el proceso de recolección valora y exige esta información, probablemente porque es esencial para el negocio o análisis de mercado regional.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">price</span></code> (0%): La variable objetivo principal está completa. Para un modelo de predicción de precios, esto es excelente. Indica que el precio no es opcional en los listados, lo cual tiene sentido comercialmente.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">state</span></code> (0%): Complementa la información regional, proporcionando contexto geográfico completo.</p></li>
</ul>
</li>
<li><p><strong>Variables con Faltantes Leves (&lt;5%)</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">year</span></code> (0.28%): Esto indica que el año del vehículo es considerado información casi obligatoria, probablemente porque afecta significativamente el valor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">odometer</span></code> (1.03%): El kilometraje está casi completo.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">transmission</span></code> (0.60%) y <code class="docutils literal notranslate"><span class="pre">fuel</span></code> (0.71%): Características técnicas básicas están muy completas. Los faltantes mínimos sugieren que son campos casi obligatorios en el formulario.</p></li>
</ul>
</li>
<li><p><strong>Variables con Faltantes Moderados (5-30%)</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">manufacturer</span></code> (4.13%): Aproximadamente en 4 de cada 100 vehículos no se registró la marca.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code> (1.24%): Interesantemente, hay más marcas faltantes que modelos.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">title_status</span></code> (1.93%): Esto indica que es información generalmente disponible pero no estrictamente obligatoria.</p></li>
</ul>
</li>
<li><p><strong>Variables con Faltantes Críticos (30-70%)</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">condition</span></code> (40.79%): Esto es alarmante porque la condición es crucial para la valoración. Sugiere que muchos vendedores omiten esta información o el campo no es obligatorio.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cylinders</span></code> (41.62%): Casi la mitad de los vehículos no especifican cilindrada. Podría deberse a que muchos vendedores no conocen esta información técnica.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">VIN</span></code> (37.73%): Más de un tercio no tiene VIN. Esto es problemático para verificación de historial. Podría indicar vehículos más antiguos o vendedores que protegen privacidad.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">drive</span></code> (30.59%): Información técnica que muchos omiten.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">paint_color</span></code> (30.50%): Casi un tercio no especifica color.</p></li>
</ul>
</li>
<li><p><strong>Variable con Faltantes Extremos (&gt;70%)</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">size</span></code> (71.77%): Casi 3 de cada 4 vehículos no tienen tamaño especificado. Esto indica que este campo probablemente no existía en formularios antiguos o fue añadido posteriormente.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">county</span></code> (100%): Variable completamente inútil. Debe eliminarse inmediatamente. Su completa ausencia sugiere que era un campo planeado pero nunca implementado.</p></li>
</ul>
</li>
</ol>
<p>El análisis revela un dataset con integridad fundamental en variables críticas como precio, ubicación e identificadores, pero con debilidades significativas en atributos descriptivos como condición, cilindrada y características técnicas. La presencia masiva de valores faltantes en variables clave sugiere problemas estructurales en la recolección de datos más que errores aleatorios.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="preprocesamiento">
<h1>Preprocesamiento<a class="headerlink" href="#preprocesamiento" title="Permalink to this heading">#</a></h1>
<p>Este proceso incluye la limpieza de datos, que implica identificar y corregir errores e inconsistencias, así como la transformación de los datos para prepararlos para el análisis. Es esencial para garantizar que los datos estén listos para el modelado e interpretación, mejorando la calidad y precisión de los resultados. Para garantizar la calidad y manejabilidad del conjunto de datos, se tomaron las siguientes decisiones de limpieza inicial: eliminación de variables y eliminación de observaciones.</p>
<section id="eliminacion-de-variables">
<h2>Eliminación de Variables<a class="headerlink" href="#eliminacion-de-variables" title="Permalink to this heading">#</a></h2>
<p>Se descartaron las columnas <code class="docutils literal notranslate"><span class="pre">['county',</span> <span class="pre">'id',</span> <span class="pre">'url',</span> <span class="pre">'region_url',</span> <span class="pre">'VIN',</span> <span class="pre">'image_url',</span> <span class="pre">'description',</span> <span class="pre">'long',</span> <span class="pre">'lat',</span> <span class="pre">'posting_date']</span></code> por las siguientes razones:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">id</span></code>, <code class="docutils literal notranslate"><span class="pre">url</span></code>, <code class="docutils literal notranslate"><span class="pre">region_url</span></code>, <code class="docutils literal notranslate"><span class="pre">image_url</span></code>: Son identificadores o enlaces únicos que no aportan valor predictivo a un modelo de machine learning.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">VIN</span></code>: El Vehicle Identification Number es un identificador que no aporta valor predictivo a un modelo de machine learning.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">description</span></code>: Es un campo de texto libre. Su procesamiento requeriría técnicas de NLP (Procesamiento de Lenguaje Natural), lo cual no está contemplado en los objetivos de este análisis.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">long</span></code> y <code class="docutils literal notranslate"><span class="pre">lat</span></code> (coordenadas geográficas): Si bien la ubicación es un factor crucial para el precio y la demanda, su tratamiento efectivo requiere de análisis geoespacial avanzado. Dado que el proyecto se centra en la aplicación de modelos de regresión lineal y logística, y para mantener un enfoque claro y reproducible, se decidió excluir estas variables, dejando su potencial análisis para un proyecto futuro.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">posting_date</span></code>: La variable temporal es extremadamente valiosa para analizar tendencias y estacionalidad. Sin embargo, su incorporación adecuada requiere un feature engineering específico (como extraer el día de la semana, el mes, o si es fin de semana). Al igual que con las coordenadas, se optó por excluirla para priorizar el alcance definido, reconociendo su potencial para un análisis más profundo posterior.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">county</span></code>: Variable completamente inútil ya que esta totalmente vacía.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;county&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;url&#39;</span><span class="p">,</span> <span class="s1">&#39;region_url&#39;</span><span class="p">,</span> <span class="s1">&#39;VIN&#39;</span><span class="p">,</span> <span class="s1">&#39;image_url&#39;</span><span class="p">,</span> <span class="s1">&#39;description&#39;</span><span class="p">,</span> <span class="s1">&#39;long&#39;</span><span class="p">,</span> <span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;posting_date&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="eliminacion-de-observaciones-con-valores-faltantes-na">
<h2>Eliminación de Observaciones con Valores Faltantes (NA)<a class="headerlink" href="#eliminacion-de-observaciones-con-valores-faltantes-na" title="Permalink to this heading">#</a></h2>
<p>Se optó por eliminar todas las filas que contuvieran al menos un valor NA. Esta decisión se basó en dos factores clave:</p>
<ul class="simple">
<li><p>El proyecto sugiere un tamaño típico del conjunto de datos final entre 15.000 y 30.000 observaciones. El dataset original, con cientos de miles de entradas, permite esta reducción sin comprometer la capacidad de los modelos para generalizar.</p></li>
<li><p>Un análisis preliminar reveló un alto porcentaje de valores nulos en varias columnas clave. Realizar una imputación robusta en tantas variables habría introducido un alto grado de incertidumbre y potencial sesgo en los datos, arriesgando la integridad del análisis. La eliminación garantiza la consistencia y calidad de los puntos de datos utilizados para el entrenamiento, resultando en un dataset más pequeño pero significativamente más limpio y confiable.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p>Se verifican los cambios realizados.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(74362, 16)
</pre></div>
</div>
</div>
</div>
</section>
<section id="valores-unicos">
<h2>Valores únicos<a class="headerlink" href="#valores-unicos" title="Permalink to this heading">#</a></h2>
<p>Se calcula el número de valores únicos para cada variable del DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>region            403
price            4050
year              101
manufacturer       41
model            9060
condition           6
cylinders           8
fuel                5
odometer        26216
title_status        6
transmission        3
drive               3
size                4
type               13
paint_color        12
state              51
dtype: int64
</pre></div>
</div>
</div>
</div>
<p><strong>Interpretación Valores únicos</strong></p>
<p>El análisis de cardinalidad de las variables categóricas y numéricas revela características fundamentales sobre la estructura y complejidad del dataset, cruciales para el diseño del pipeline de preprocesamiento. Se observa una cardinalidad extremadamente alta en la variable <code class="docutils literal notranslate"><span class="pre">model</span></code> (9,530 valores únicos), lo que presenta un desafío significativo para técnicas de codificación como One-Hot Encoding, ya que generaría una matriz de features excesivamente amplia y dispersa, incrementando la dimensionalidad y el riesgo de sobreajuste. La variable <code class="docutils literal notranslate"><span class="pre">manufacturer</span></code> (41 únicos) y <code class="docutils literal notranslate"><span class="pre">region</span></code> (403 únicos) también muestran una cardinalidad media-alta, manejable pero que requerirá una cuidadosa consideración. Por otro lado, variables como <code class="docutils literal notranslate"><span class="pre">transmission</span></code> (3), <code class="docutils literal notranslate"><span class="pre">fuel</span></code> (5), <code class="docutils literal notranslate"><span class="pre">title_status</span></code> (6), <code class="docutils literal notranslate"><span class="pre">drive</span></code> (3), y <code class="docutils literal notranslate"><span class="pre">condition</span></code> (6) exhiben una baja cardinalidad, lo que las hace ideales para ser codificadas sin mayor complicación. La presencia de 51 valores únicos en <code class="docutils literal notranslate"><span class="pre">state</span></code> confirma su uso como variable categórica geográfica. Para las variables numéricas, el alto número de valores únicos en <code class="docutils literal notranslate"><span class="pre">year</span></code>, <code class="docutils literal notranslate"><span class="pre">odometer</span></code>, y <code class="docutils literal notranslate"><span class="pre">price</span></code> es el comportamiento esperado y confirma su naturaleza continua, validando la decisión de escalarlas. Este perfil de cardinalidad sugiere la potencial necesidad de estrategias adicionales para variables como <code class="docutils literal notranslate"><span class="pre">model</span></code>, como agrupar modelos poco frecuentes en una categoría “Other” o utilizar técnicas de encoding alternativas, para garantizar la eficiencia y efectividad de los modelos de machine learning.</p>
</section>
<section id="creacion-de-la-variable-binaria-highdemand">
<h2>Creación de la Variable Binaria “HighDemand”<a class="headerlink" href="#creacion-de-la-variable-binaria-highdemand" title="Permalink to this heading">#</a></h2>
<p>Para la tarea de clasificación binaria especificada en los objetivos del proyecto, se creó la variable objetivo <code class="docutils literal notranslate"><span class="pre">HighDemand</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;HighDemand&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">())</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Se verifican los cambios realizados.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(74362, 17)
</pre></div>
</div>
</div>
</div>
</section>
<section id="separacion-de-los-conjutos-x-y-reg-y-clf">
<h2>Separación de los conjutos X, y_reg, y_clf<a class="headerlink" href="#separacion-de-los-conjutos-x-y-reg-y-clf" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categorical_cols</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

<span class="n">numeric_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;year&quot;</span><span class="p">,</span> <span class="s2">&quot;odometer&quot;</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">categorical_cols</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">numeric_cols</span><span class="p">]</span>

<span class="n">y_reg</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;price&quot;</span><span class="p">]</span>
<span class="n">y_clf</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;HighDemand&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="analisis-de-correlacion-no-parametrica-para-variables-numericas-spearman">
<h2>Análisis de Correlación No Paramétrica para Variables Numéricas (Spearman)<a class="headerlink" href="#analisis-de-correlacion-no-parametrica-para-variables-numericas-spearman" title="Permalink to this heading">#</a></h2>
<p>Tras los resultados obtenidos en los análisis anteriores, se evidenció la necesidad de emplear métodos estadísticos robustos que no dependieran de supuestos restrictivos como la normalidad de los datos o la linealidad perfecta de las relaciones. Para evaluar la asociación entre las variables numéricas predictoras (year, odometer) y la variable objetivo price, se utilizó el coeficiente de correlación de Spearman.</p>
<p>A diferencia del coeficiente de Pearson, que mide únicamente la relación lineal, el coeficiente de Spearman evalúa relaciones monótonas (ya sean lineales o no lineales, siempre que la tendencia sea constante). Además, al basarse en los rangos de los datos en lugar de sus valores brutos, es mucho menos sensible a outliers, lo que lo hace ideal para analizar variables como el precio, que suelen presentar valores extremos y distribuciones sesgadas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resultados</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">numeric_cols</span><span class="p">:</span>
    <span class="n">corr</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">y_reg</span><span class="p">)</span>
    <span class="n">resultados</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Corr&quot;</span><span class="p">:</span> <span class="n">corr</span><span class="p">,</span> <span class="s2">&quot;p_value&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">}</span>

<span class="n">spearman_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">resultados</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;Corr&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">spearman_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Corr</th>
      <th>p_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>year</th>
      <td>0.535153</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>odometer</th>
      <td>-0.460547</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="agrupamiento-de-variables-categoricas-de-alta-cardinalidad">
<h2>Agrupamiento de Variables Categóricas de Alta Cardinalidad<a class="headerlink" href="#agrupamiento-de-variables-categoricas-de-alta-cardinalidad" title="Permalink to this heading">#</a></h2>
<p>En el análisis de datos, las variables categóricas con un gran número de categorías o niveles —conocidas como variables de alta cardinalidad— representan un desafío importante. Estas variables pueden dificultar la construcción de modelos debido al exceso de niveles poco representativos, la presencia de categorías con muy baja frecuencia y el aumento de la dimensionalidad al aplicar técnicas de codificación. Para superar este problema, una estrategia común es el agrupamiento de categorías, que consiste en combinar o reducir los niveles de la variable de manera que se conserven patrones relevantes y se minimice la pérdida de información. Este proceso permite simplificar la estructura de los datos, mejorar la eficiencia de los algoritmos de modelado y, en muchos casos, aumentar la capacidad predictiva de los modelos al evitar el sobreajuste.</p>
<section id="preservacion-selectiva-de-modelos-por-frecuencia">
<h3>Preservación Selectiva de Modelos por Frecuencia<a class="headerlink" href="#preservacion-selectiva-de-modelos-por-frecuencia" title="Permalink to this heading">#</a></h3>
<p>Para abordar el desafío más crítico de cardinalidad en el dataset la variable <code class="docutils literal notranslate"><span class="pre">model</span></code> con 9,530 categorías únicas se implementó una  metodología consistió en mantener los modelos con una frecuencua mayor a 5 observaciones, las demás instanscias serán recategorizadas como <code class="docutils literal notranslate"><span class="pre">&quot;other&quot;</span></code>.</p>
<p><strong>Cardinalidad extrema:</strong> La variable representaba el mayor riesgo de sobreajuste por dimensionalidad, haciendo esencial una reducción drástica pero inteligente.</p>
<p><strong>Impacto obtenido:</strong> Esta intervención redujo la cardinalidad a un número manejable, transformando una variable inutilizable en una característica viable para el modelado predictivo.</p>
<hr class="docutils" />
<p><strong>Alternativa Considerada: Eliminación Pura de la Variable</strong></p>
<p>Se evaluó la opción más conservadora de eliminar completamente la variable del modelo:</p>
<p><strong>Criterio propuesto:</strong> “Eliminar la variable <code class="docutils literal notranslate"><span class="pre">model</span></code> y confiar en que las demás características (<code class="docutils literal notranslate"><span class="pre">manufacturer</span></code>, <code class="docutils literal notranslate"><span class="pre">type</span></code>, <code class="docutils literal notranslate"><span class="pre">year</span></code>, etc.) capturen suficiente varianza explicativa.”</p>
<p><strong>Ventajas de la alternativa:</strong></p>
<ul class="simple">
<li><p>Eliminación completa del problema de cardinalidad</p></li>
<li><p>Simplificación radical del pipeline de preprocesamiento</p></li>
<li><p>Reducción del riesgo de sobreajuste por variables correlacionadas</p></li>
</ul>
<p><strong>Limitaciones que motivaron su descarte:</strong></p>
<ul class="simple">
<li><p>Pérdida irreversible de información valiosa sobre modelos específicos que afectan significativamente el precio</p></li>
<li><p>Incapacidad para capturar el efecto de modelos icónicos dentro de una marca</p></li>
<li><p>Reducción potencial del poder predictivo del modelo</p></li>
</ul>
<p><strong>Decisión final:</strong> Se optó por la estrategia de agrupamiento para transformar una variable problemática en un recurso valioso. Este enfoque demuestra cómo el conocimiento del dominio automotriz (reconocer que la importancia de un modelo depende de su marca) puede informar técnicamente las decisiones de preprocesamiento. La solución implementada representa el balance ideal entre sofisticación técnica y pragmatismo aplicado.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">umbral</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">modelos_a_agrupar</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">umbral</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">X</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;other&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">modelos_a_agrupar</span> <span class="k">else</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>region            403
manufacturer       41
model            2080
condition           6
cylinders           8
fuel                5
title_status        6
transmission        3
drive               3
size                4
type               13
paint_color        12
state              51
year              101
odometer        26216
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Se muestran las primeras filas del DataFrame con todos los detalles.<br />
Se usa <code class="docutils literal notranslate"><span class="pre">.to_string()</span></code> para evitar el truncamiento de columnas y lograr mostrar todas las variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    region manufacturer            model  condition    cylinders    fuel title_status transmission drive       size      type paint_color state    year  odometer
31  auburn         ford        f-150 xlt  excellent  6 cylinders     gas        clean    automatic   rwd  full-size     truck       black    al  2013.0  128000.0
55  auburn         ford  f250 super duty       good  8 cylinders  diesel        clean    automatic   4wd  full-size    pickup        blue    al  2004.0   88000.0
59  auburn        honda          odyssey  excellent  6 cylinders     gas        clean    automatic   fwd  full-size  mini-van      silver    al  2012.0   95000.0
65  auburn         ford             f450       good  8 cylinders  diesel        clean       manual   rwd  full-size     truck       white    al  2001.0  144700.0
73  auburn        dodge            other  excellent  8 cylinders     gas      rebuilt    automatic   rwd   mid-size     sedan        grey    al  2017.0   90000.0
</pre></div>
</div>
</div>
</div>
<p>Se muestran las últimas filas del DataFrame con todos los detalles.<br />
Se usa <code class="docutils literal notranslate"><span class="pre">.to_string()</span></code> para evitar el truncamiento de columnas y lograr mostrar todas las variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>         region manufacturer                    model  condition    cylinders fuel title_status transmission drive         size         type paint_color state    year  odometer
426793  wyoming    chevrolet                cruze, lt  excellent  4 cylinders  gas        clean    automatic   fwd     mid-size        sedan       black    wy  2018.0   36465.0
426808  wyoming    chevrolet    silverado 1500 lt 4x4  excellent  8 cylinders  gas         lien    automatic   4wd    full-size        truck        blue    wy  2005.0  130000.0
426809  wyoming         jeep                    other       good  8 cylinders  gas        clean    automatic   4wd    full-size          SUV       black    wy  1990.0  114400.0
426831  wyoming       nissan  300zx coupe with t-tops   like new  6 cylinders  gas        clean    automatic   rwd  sub-compact    hatchback         red    wy  1985.0  115000.0
426833  wyoming       jaguar          xk8 convertible       good  8 cylinders  gas        clean    automatic   rwd      compact  convertible       white    wy  1997.0   69550.0
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="analisis-de-relevancia-de-variables-categoricas-prueba-de-kruskal-wallis">
<h2>Análisis de Relevancia de Variables Categóricas (Prueba de Kruskal-Wallis)<a class="headerlink" href="#analisis-de-relevancia-de-variables-categoricas-prueba-de-kruskal-wallis" title="Permalink to this heading">#</a></h2>
<p>Kruskall-Wallis es la alternativa no paramétrica al ANOVA de una vía. No asume normalidad en los datos y es menos sensible a outliers, ya que trabaja con los rangos de los datos en lugar de sus valores absolutos. Evalúa la hipótesis nula de que las medianas de price son iguales entre todas las categorías de una variable.</p>
<ul class="simple">
<li><p>H₀: Las medianas del precio son iguales en todos los grupos.</p></li>
<li><p>H₁: Al menos un grupo tiene una mediana del precio diferente.</p></li>
</ul>
<p>El estadístico H obtenido indica la magnitud de la diferencia entre los grupos, donde un valor más alto sugiere una variable más relevante para predecir el precio.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categorical_cols</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resultados</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categorical_cols</span><span class="p">:</span>
    <span class="n">grupos</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_reg</span><span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">==</span> <span class="n">cat</span><span class="p">]</span> <span class="k">for</span> <span class="n">cat</span> <span class="ow">in</span> <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()]</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">grupos</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">stat</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">kruskal</span><span class="p">(</span><span class="o">*</span><span class="n">grupos</span><span class="p">)</span>
        <span class="n">resultados</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;H&quot;</span><span class="p">:</span> <span class="n">stat</span><span class="p">,</span> <span class="s2">&quot;p_value&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">}</span>

<span class="n">kruskal_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">resultados</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;H&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">kruskal_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                         H        p_value
model         29076.876775   0.000000e+00
type          13870.815801   0.000000e+00
drive          9657.959249   0.000000e+00
condition      8628.766865   0.000000e+00
manufacturer   7686.684655   0.000000e+00
region         6818.696503   0.000000e+00
cylinders      6241.293779   0.000000e+00
fuel           5419.093383   0.000000e+00
size           4797.823188   0.000000e+00
paint_color    3180.962528   0.000000e+00
state          3074.011575   0.000000e+00
title_status    717.458397  8.245503e-153
transmission    654.636701  7.037956e-143
</pre></div>
</div>
</div>
</div>
</section>
<section id="seleccion-de-variables-basada-en-relevancia-predictiva-y-manejo-de-categoricas">
<h2>Selección de Variables Basada en Relevancia Predictiva y Manejo de Categoricas<a class="headerlink" href="#seleccion-de-variables-basada-en-relevancia-predictiva-y-manejo-de-categoricas" title="Permalink to this heading">#</a></h2>
<p>Como parte del proceso de optimización del modelo y con el objetivo de maximizar su poder predictivo, se llevó a cabo una evaluación exhaustiva de la contribución individual de cada variable mediante análisis estadístico no paramétrico (prueba de Kruskal-Wallis). Este análisis permitió cuantificar la capacidad de cada característica para discriminar entre los diferentes rangos de precio en el conjunto de datos.</p>
<p>Contrario a un enfoque de eliminación, el análisis reveló que todas las variables consideradas mostraron un grado de relevancia estadística en la explicación de la variabilidad del precio. Si bien se identificaron diferencias en la magnitud del estadístico H entre variables, cada una aporta información valiosa y única al modelo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categorical_cols</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">categorical_cols</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;region&#39;, &#39;manufacturer&#39;, &#39;model&#39;, &#39;condition&#39;, &#39;cylinders&#39;, &#39;fuel&#39;,
       &#39;title_status&#39;, &#39;transmission&#39;, &#39;drive&#39;, &#39;size&#39;, &#39;type&#39;, &#39;paint_color&#39;,
       &#39;state&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="configuracion-de-la-busqueda-de-hiperparametros-con-gridsearchcv">
<h2>Configuración de la Búsqueda de Hiperparámetros con GridSearchCV<a class="headerlink" href="#configuracion-de-la-busqueda-de-hiperparametros-con-gridsearchcv" title="Permalink to this heading">#</a></h2>
<p>Para optimizar el rendimiento de los modelos de manera eficiente y encontrar el valor óptimo de los hiperparámetros de regularización, se utilizaron los métodos de validación cruzada integrados en scikit-learn: <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code>, <code class="docutils literal notranslate"><span class="pre">LassoCV</span></code> y <code class="docutils literal notranslate"><span class="pre">LogisticRegressionCV</span></code>. Estos algoritmos realizan una búsqueda automatizada del mejor hiperparámetro mediante validación cruzada integrada, ofreciendo una implementación más optimizada y computacionalmente eficiente que una configuración manual de GridSearchCV.</p>
<p>Estrategia de Implementación:</p>
<p><code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> y <code class="docutils literal notranslate"><span class="pre">LassoCV</span></code>: Realizan una búsqueda sobre un rango predefinido de valores de alpha (fuerza de regularización) mediante validación cruzada, seleccionando automáticamente el valor que minimiza el error cuadrático medio.</p>
<p><code class="docutils literal notranslate"><span class="pre">LogisticRegressionCV</span></code>: Realiza una búsqueda similar para el parámetro C (inversa de la fuerza de regularización) utilizando validación cruzada estratificada, crucial para mantener la proporción de clases en cada fold en problemas de clasificación.</p>
<p>Los hiperparámetros a optimizar son:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">alpha</span></code> para Ridge y Lasso, que controla la fuerza de la regularización.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code> para Regresión Logística, que controla la inversa de la fuerza de la regularización.</p></li>
</ul>
</section>
<section id="prepocesamiento-variables-categoricas-y-numericas">
<h2>Prepocesamiento variables categóricas y numéricas<a class="headerlink" href="#prepocesamiento-variables-categoricas-y-numericas" title="Permalink to this heading">#</a></h2>
<p>La configuración del preprocesador especifica dos transformaciones en paralelo:</p>
<ol class="arabic simple">
<li><p><strong>Escalado estandarizado</strong> para variables numéricas continuas.</p></li>
<li><p><strong>Codificación one-hot</strong> con eliminación de la primera categoría para evitar multicolinealidad en las variables categóricas.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>


<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_num</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">numeric_cols</span><span class="p">])</span>

<span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">X_cat</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">categorical_cols</span><span class="p">])</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">X_num</span><span class="p">,</span> <span class="n">X_cat</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="creacion-de-conjuntos-de-entrenamiento-y-prueba">
<h2>Creación de Conjuntos de Entrenamiento y Prueba<a class="headerlink" href="#creacion-de-conjuntos-de-entrenamiento-y-prueba" title="Permalink to this heading">#</a></h2>
<p>Para evaluar de manera rigurosa y justa el desempeño final de los modelos optimizados, es esencial probarlos en datos que no hayan sido vistos durante el proceso de ajuste de hiperparámetros. Por esta razón, se divide el dataset en subconjuntos de entrenamiento y prueba. El conjunto de entrenamiento (<code class="docutils literal notranslate"><span class="pre">X_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>) se utilizará para reentrenar el mejor modelo encontrado por <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> con todos los datos disponibles de entrenamiento, mientras que el conjunto de prueba (<code class="docutils literal notranslate"><span class="pre">X_test</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>) se reservará exclusivamente para la evaluación final, proporcionando una estimación no sesgada del rendimiento del modelo en datos nuevos.</p>
<p>La división se realiza dos veces de manera independiente:</p>
<ol class="arabic simple">
<li><p>Para la tarea de Regresión: Se divide las features (<code class="docutils literal notranslate"><span class="pre">X</span></code>) y la variable objetivo continua (<code class="docutils literal notranslate"><span class="pre">y_reg</span></code>).</p></li>
<li><p>Para la tarea de Clasificación: Se divide las features (<code class="docutils literal notranslate"><span class="pre">X</span></code>) y la variable objetivo binaria (<code class="docutils literal notranslate"><span class="pre">y_clf</span></code>), utilizando el parámetro <code class="docutils literal notranslate"><span class="pre">stratify</span></code> para garantizar que la proporción de las clases <code class="docutils literal notranslate"><span class="pre">HighDemand</span></code> se mantenga igual en ambos conjuntos, preservando así el balance original.</p></li>
</ol>
<p>Un 20% de los datos se asigna para prueba en ambos casos, utilizando una semilla (<code class="docutils literal notranslate"><span class="pre">random_state=42</span></code>) para asegurar la reproducibilidad de la partición.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_reg</span><span class="p">,</span> <span class="n">X_test_reg</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">,</span> <span class="n">y_test_reg</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_reg</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">X_train_clf</span><span class="p">,</span> <span class="n">X_test_clf</span><span class="p">,</span> <span class="n">y_train_clf</span><span class="p">,</span> <span class="n">y_test_clf</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_clf</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_clf</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="ejecucion-de-la-busqueda-de-hiperparametros-y-entrenamiento-de-los-modelos">
<h2>Ejecución de la Búsqueda de Hiperparámetros y Entrenamiento de los Modelos<a class="headerlink" href="#ejecucion-de-la-busqueda-de-hiperparametros-y-entrenamiento-de-los-modelos" title="Permalink to this heading">#</a></h2>
<p>Una vez configuradas las estrategias de búsqueda, se procede a ejecutar el entrenamiento de los modelos. Este paso es donde se implementa de manera práctica el flujo completo de machine learning definido teóricamente. El método <code class="docutils literal notranslate"><span class="pre">fit()</span></code> de cada objeto no solo entrena el modelo final con la mejor combinación de hiperparámetros encontrada, sino que realiza de manera automatizada y segura todo el proceso de validación cruzada, preprocesamiento y optimización.</p>
<p>Los hiperparámetros a optimizar son:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">alpha</span></code> para Ridge y Lasso, que controla la fuerza de la regularización.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code> para Regresión Logística, que controla la inversa de la fuerza de la regularización.</p></li>
</ul>
<section id="ridge">
<h3>Ridge<a class="headerlink" href="#ridge" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">ridge_cv</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">ridge_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reg</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">)</span>

<span class="n">best_alpha</span> <span class="o">=</span> <span class="n">ridge_cv</span><span class="o">.</span><span class="n">alpha_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Resultados RidgeCV ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor alpha:&quot;</span><span class="p">,</span> <span class="n">best_alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">34</span><span class="p">],</span> <span class="n">line</span> <span class="mi">6</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">ridge_cv</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">6</span> <span class="n">ridge_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reg</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="n">best_alpha</span> <span class="o">=</span> <span class="n">ridge_cv</span><span class="o">.</span><span class="n">alpha_</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Resultados RidgeCV ---&quot;</span><span class="p">)</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\linear_model\_ridge.py:2360,</span> in <span class="ni">RidgeCV.fit</span><span class="nt">(self, X, y, sample_weight)</span>
<span class="g g-Whitespace">   </span><span class="mi">2330</span><span class="w"> </span><span class="sd">&quot;&quot;&quot;Fit Ridge regression model with cv.</span>
<span class="g g-Whitespace">   </span><span class="mi">2331</span><span class="sd"> </span>
<span class="g g-Whitespace">   </span><span class="mi">2332</span><span class="sd"> Parameters</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">   </span><span class="mi">2356</span><span class="sd"> the validation score.</span>
<span class="g g-Whitespace">   </span><span class="mi">2357</span><span class="sd"> &quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">2358</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>
<span class="ne">-&gt; </span><span class="mi">2360</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2361</span> <span class="k">return</span> <span class="bp">self</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\linear_model\_ridge.py:2184,</span> in <span class="ni">_BaseRidgeCV.fit</span><span class="nt">(self, X, y, sample_weight)</span>
<span class="g g-Whitespace">   </span><span class="mi">2174</span> <span class="n">model</span> <span class="o">=</span> <span class="n">RidgeClassifier</span> <span class="k">if</span> <span class="n">is_classifier</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="k">else</span> <span class="n">Ridge</span>
<span class="g g-Whitespace">   </span><span class="mi">2175</span> <span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">2176</span>     <span class="n">model</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">2177</span>         <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2182</span>     <span class="n">scoring</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2183</span> <span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">2184</span> <span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2185</span> <span class="n">estimator</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="g g-Whitespace">   </span><span class="mi">2186</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">alpha</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\model_selection\_search.py:874,</span> in <span class="ni">BaseSearchCV.fit</span><span class="nt">(self, X, y, groups, **fit_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">868</span>     <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_results</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">869</span>         <span class="n">all_candidate_params</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">,</span> <span class="n">all_out</span><span class="p">,</span> <span class="n">all_more_results</span>
<span class="g g-Whitespace">    </span><span class="mi">870</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">872</span>     <span class="k">return</span> <span class="n">results</span>
<span class="ne">--&gt; </span><span class="mi">874</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_search</span><span class="p">(</span><span class="n">evaluate_candidates</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">876</span> <span class="c1"># multimetric is determined here because in the case of a callable</span>
<span class="g g-Whitespace">    </span><span class="mi">877</span> <span class="c1"># self.scoring the return type is only known after calling</span>
<span class="g g-Whitespace">    </span><span class="mi">878</span> <span class="n">first_test_score</span> <span class="o">=</span> <span class="n">all_out</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;test_scores&quot;</span><span class="p">]</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\model_selection\_search.py:1388,</span> in <span class="ni">GridSearchCV._run_search</span><span class="nt">(self, evaluate_candidates)</span>
<span class="g g-Whitespace">   </span><span class="mi">1386</span> <span class="k">def</span> <span class="nf">_run_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">evaluate_candidates</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1387</span><span class="w">     </span><span class="sd">&quot;&quot;&quot;Search all candidates in param_grid&quot;&quot;&quot;</span>
<span class="ne">-&gt; </span><span class="mi">1388</span>     <span class="n">evaluate_candidates</span><span class="p">(</span><span class="n">ParameterGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">))</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\model_selection\_search.py:821,</span> in <span class="ni">BaseSearchCV.fit.&lt;locals&gt;.evaluate_candidates</span><span class="nt">(candidate_params, cv, more_results)</span>
<span class="g g-Whitespace">    </span><span class="mi">813</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">814</span>     <span class="nb">print</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">815</span>         <span class="s2">&quot;Fitting </span><span class="si">{0}</span><span class="s2"> folds for each of </span><span class="si">{1}</span><span class="s2"> candidates,&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">816</span>         <span class="s2">&quot; totalling </span><span class="si">{2}</span><span class="s2"> fits&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">817</span>             <span class="n">n_splits</span><span class="p">,</span> <span class="n">n_candidates</span><span class="p">,</span> <span class="n">n_candidates</span> <span class="o">*</span> <span class="n">n_splits</span>
<span class="g g-Whitespace">    </span><span class="mi">818</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">819</span>     <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">821</span> <span class="n">out</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">822</span>     <span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_score</span><span class="p">)(</span>
<span class="g g-Whitespace">    </span><span class="mi">823</span>         <span class="n">clone</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">824</span>         <span class="n">X</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">825</span>         <span class="n">y</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">826</span>         <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">827</span>         <span class="n">test</span><span class="o">=</span><span class="n">test</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">828</span>         <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">829</span>         <span class="n">split_progress</span><span class="o">=</span><span class="p">(</span><span class="n">split_idx</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">830</span>         <span class="n">candidate_progress</span><span class="o">=</span><span class="p">(</span><span class="n">cand_idx</span><span class="p">,</span> <span class="n">n_candidates</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">831</span>         <span class="o">**</span><span class="n">fit_and_score_kwargs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">832</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">833</span>     <span class="k">for</span> <span class="p">(</span><span class="n">cand_idx</span><span class="p">,</span> <span class="n">parameters</span><span class="p">),</span> <span class="p">(</span><span class="n">split_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">834</span>         <span class="nb">enumerate</span><span class="p">(</span><span class="n">candidate_params</span><span class="p">),</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">835</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">836</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">838</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">839</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">840</span>         <span class="s2">&quot;No fits were performed. &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">841</span>         <span class="s2">&quot;Was the CV iterator empty? &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">842</span>         <span class="s2">&quot;Were there no candidates?&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">843</span>     <span class="p">)</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\utils\parallel.py:63,</span> in <span class="ni">Parallel.__call__</span><span class="nt">(self, iterable)</span>
<span class="g g-Whitespace">     </span><span class="mi">58</span> <span class="n">config</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">59</span> <span class="n">iterable_with_config</span> <span class="o">=</span> <span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span>     <span class="p">(</span><span class="n">_with_config</span><span class="p">(</span><span class="n">delayed_func</span><span class="p">,</span> <span class="n">config</span><span class="p">),</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span>     <span class="k">for</span> <span class="n">delayed_func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span> <span class="ow">in</span> <span class="n">iterable</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span> <span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">63</span> <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">iterable_with_config</span><span class="p">)</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\joblib\parallel.py:1863,</span> in <span class="ni">Parallel.__call__</span><span class="nt">(self, iterable)</span>
<span class="g g-Whitespace">   </span><span class="mi">1861</span>     <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_sequential_output</span><span class="p">(</span><span class="n">iterable</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1862</span>     <span class="nb">next</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1863</span>     <span class="k">return</span> <span class="n">output</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_generator</span> <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1865</span> <span class="c1"># Let&#39;s create an ID that uniquely identifies the current call. If the</span>
<span class="g g-Whitespace">   </span><span class="mi">1866</span> <span class="c1"># call is interrupted early and that the same instance is immediately</span>
<span class="g g-Whitespace">   </span><span class="mi">1867</span> <span class="c1"># re-used, this id will be used to prevent workers that were</span>
<span class="g g-Whitespace">   </span><span class="mi">1868</span> <span class="c1"># concurrently finalizing a task from the previous call to run the</span>
<span class="g g-Whitespace">   </span><span class="mi">1869</span> <span class="c1"># callback.</span>
<span class="g g-Whitespace">   </span><span class="mi">1870</span> <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\joblib\parallel.py:1792,</span> in <span class="ni">Parallel._get_sequential_output</span><span class="nt">(self, iterable)</span>
<span class="g g-Whitespace">   </span><span class="mi">1790</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dispatched_batches</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="g g-Whitespace">   </span><span class="mi">1791</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dispatched_tasks</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="ne">-&gt; </span><span class="mi">1792</span> <span class="n">res</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1793</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_completed_tasks</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="g g-Whitespace">   </span><span class="mi">1794</span> <span class="bp">self</span><span class="o">.</span><span class="n">print_progress</span><span class="p">()</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\utils\parallel.py:123,</span> in <span class="ni">_FuncWrapper.__call__</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">121</span>     <span class="n">config</span> <span class="o">=</span> <span class="p">{}</span>
<span class="g g-Whitespace">    </span><span class="mi">122</span> <span class="k">with</span> <span class="n">config_context</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">123</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\model_selection\_validation.py:686,</span> in <span class="ni">_fit_and_score</span><span class="nt">(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)</span>
<span class="g g-Whitespace">    </span><span class="mi">684</span>         <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">685</span>     <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">686</span>         <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">688</span> <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">689</span>     <span class="c1"># Note fit time as time until error</span>
<span class="g g-Whitespace">    </span><span class="mi">690</span>     <span class="n">fit_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\linear_model\_ridge.py:1134,</span> in <span class="ni">Ridge.fit</span><span class="nt">(self, X, y, sample_weight)</span>
<span class="g g-Whitespace">   </span><span class="mi">1125</span> <span class="n">_accept_sparse</span> <span class="o">=</span> <span class="n">_get_valid_accept_sparse</span><span class="p">(</span><span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span>     <span class="n">X</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span>     <span class="n">y</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span>     <span class="n">y_numeric</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1133</span> <span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1134</span> <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\linear_model\_ridge.py:900,</span> in <span class="ni">_BaseRidge.fit</span><span class="nt">(self, X, y, sample_weight)</span>
<span class="g g-Whitespace">    </span><span class="mi">896</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">897</span>         <span class="c1"># for dense matrices or when intercept is set to 0</span>
<span class="g g-Whitespace">    </span><span class="mi">898</span>         <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
<span class="ne">--&gt; </span><span class="mi">900</span>     <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="n">_ridge_regression</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">901</span>         <span class="n">X</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">902</span>         <span class="n">y</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">903</span>         <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">904</span>         <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">905</span>         <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">906</span>         <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">907</span>         <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">908</span>         <span class="n">positive</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">positive</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">909</span>         <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">910</span>         <span class="n">return_n_iter</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">911</span>         <span class="n">return_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">912</span>         <span class="n">check_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">913</span>         <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">914</span>         <span class="o">**</span><span class="n">params</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">915</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">916</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_set_intercept</span><span class="p">(</span><span class="n">X_offset</span><span class="p">,</span> <span class="n">y_offset</span><span class="p">,</span> <span class="n">X_scale</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">918</span> <span class="k">return</span> <span class="bp">self</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\linear_model\_ridge.py:708,</span> in <span class="ni">_ridge_regression</span><span class="nt">(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, positive, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input, fit_intercept)</span>
<span class="g g-Whitespace">    </span><span class="mi">706</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">707</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">708</span>         <span class="n">coef</span> <span class="o">=</span> <span class="n">_solve_cholesky</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">709</span>     <span class="k">except</span> <span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">710</span>         <span class="c1"># use SVD solver if matrix is singular</span>
<span class="g g-Whitespace">    </span><span class="mi">711</span>         <span class="n">solver</span> <span class="o">=</span> <span class="s2">&quot;svd&quot;</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\linear_model\_ridge.py:209,</span> in <span class="ni">_solve_cholesky</span><span class="nt">(X, y, alpha)</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">207</span> <span class="n">n_targets</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="ne">--&gt; </span><span class="mi">209</span> <span class="n">A</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dense_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">210</span> <span class="n">Xy</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dense_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">212</span> <span class="n">one_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

<span class="nn">File ~\miniconda3\envs\ml_venv\lib\site-packages\sklearn\utils\extmath.py:189,</span> in <span class="ni">safe_sparse_dot</span><span class="nt">(a, b, dense_output)</span>
<span class="g g-Whitespace">    </span><span class="mi">187</span>         <span class="n">ret</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">188</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">189</span>     <span class="n">ret</span> <span class="o">=</span> <span class="n">a</span> <span class="o">@</span> <span class="n">b</span>
<span class="g g-Whitespace">    </span><span class="mi">191</span> <span class="k">if</span> <span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">192</span>     <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">193</span>     <span class="ow">and</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">194</span>     <span class="ow">and</span> <span class="n">dense_output</span>
<span class="g g-Whitespace">    </span><span class="mi">195</span>     <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="s2">&quot;toarray&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">196</span> <span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">197</span>     <span class="k">return</span> <span class="n">ret</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="lasso">
<h3>Lasso<a class="headerlink" href="#lasso" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">lasso_cv</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">lasso_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reg</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">)</span>

<span class="n">best_alpha</span> <span class="o">=</span> <span class="n">lasso_cv</span><span class="o">.</span><span class="n">alpha_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Resultados LassoCV ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor alpha:&quot;</span><span class="p">,</span> <span class="n">best_alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Resultados LassoCV ---
Mejor alpha: 0.1
</pre></div>
</div>
</div>
</div>
</section>
<section id="regresion-logistica">
<h3>Regresión Logística<a class="headerlink" href="#regresion-logistica" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="n">C</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>

<span class="n">logreg_cv</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">Cs</span><span class="o">=</span><span class="n">C</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l2&quot;</span><span class="p">,</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">)</span>

<span class="n">logreg_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_clf</span><span class="p">,</span> <span class="n">y_train_clf</span><span class="p">)</span>

<span class="n">best_C</span> <span class="o">=</span> <span class="n">logreg_cv</span><span class="o">.</span><span class="n">C_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Resultados LogisticRegressionCV ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor C:&quot;</span><span class="p">,</span> <span class="n">best_C</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Resultados LogisticRegressionCV ---
Mejor C: 10.0
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="analisis-de-los-resultados-de-la-busqueda-de-hiperparametros">
<h2>Análisis de los Resultados de la Búsqueda de Hiperparámetros<a class="headerlink" href="#analisis-de-los-resultados-de-la-busqueda-de-hiperparametros" title="Permalink to this heading">#</a></h2>
<p>Tras completar el proceso de búsqueda exhaustiva, se extraen y analizan los resultados óptimos para cada modelo. Esta etapa es crucial para identificar la configuración de hiperparámetros que maximiza el rendimiento de cada algoritmo según la métrica de evaluación definida. Los resultados se presentan mostrando la mejor combinación de parámetros encontrada y su score de validación cruzada correspondiente.</p>
<p>Es importante notar que para los modelos de regresión (Ridge y Lasso), el score reportado por <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> es el negative mean squared error (<code class="docutils literal notranslate"><span class="pre">neg_mean_squared_error</span></code>). Por convención de scikit-learn, este valor se negativiza para que el algoritmo de optimización siempre busque maximizar el score. Por lo tanto, para interpretar el resultado en la escala original del Error Cuadrático Medio (MSE), es necesario multiplicar el valor por -1, obteniendo así el MSE promedio en la validación cruzada. Para el modelo de clasificación (Regresión Logística), el score de precisión (accuracy) se reporta directamente en su escala interpretable.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="evaluacion-de-desempeno">
<h1>Evaluación de desempeño<a class="headerlink" href="#evaluacion-de-desempeno" title="Permalink to this heading">#</a></h1>
<p>La evaluación de desempeño es una etapa fundamental en el desarrollo de modelos de machine learning, ya que permite medir qué tan bien se ajusta el modelo a los datos y, sobre todo, qué capacidad tiene para generalizar en situaciones no vistas. A través de métricas específicas (que varían según si se trata de un problema de regresión o de clasificación) es posible identificar fortalezas y debilidades del modelo, así como comparar diferentes enfoques y versiones durante el proceso de experimentación. Además de las métricas numéricas, las visualizaciones como matrices de confusión, curvas ROC o gráficos de predicciones frente a valores reales ofrecen una perspectiva más clara sobre el rendimiento alcanzado. De esta manera, la evaluación del desempeño no solo valida la efectividad del modelo, sino que también orienta la toma de decisiones para su mejora continua.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Gráfica Ridge</span>

<span class="n">y_pred_ridge</span> <span class="o">=</span> <span class="n">ridge_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reg</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Evaluación Ridge (Test) ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RMSE:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R²:&quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">y_test_reg</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_test_reg</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
         <span class="p">[</span><span class="n">y_test_reg</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_test_reg</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
         <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Valores reales&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicciones&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Predicciones vs Valores Reales - Lasso&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1">#Gráfica Lasso</span>


<span class="n">y_pred_lasso</span> <span class="o">=</span> <span class="n">lasso_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reg</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Evaluación Ridge (Test) ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RMSE:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R²:&quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test_reg</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">y_test_reg</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_test_reg</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
         <span class="p">[</span><span class="n">y_test_reg</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_test_reg</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
         <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Valores reales&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicciones&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Predicciones vs Valores Reales - Lasso&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Evaluación Ridge (Test) ---
MAE: 4301.411473216919
RMSE: 6357.318009836137
R²: 0.6829187266031913
</pre></div>
</div>
<img alt="_images/842ac6207cf93c7bd260120d54be68c9ee1e15c6678439b5ef5d252a37e96d17.png" src="_images/842ac6207cf93c7bd260120d54be68c9ee1e15c6678439b5ef5d252a37e96d17.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Evaluación Ridge (Test) ---
MAE: 4293.697246841724
RMSE: 6358.30376795713
R²: 0.6828203864941097
</pre></div>
</div>
<img alt="_images/f881e275a4e9e8b10d0e3f87d9878cb02d71aaddd63bf128cb3637f5a3591831.png" src="_images/f881e275a4e9e8b10d0e3f87d9878cb02d71aaddd63bf128cb3637f5a3591831.png" />
</div>
</div>
<section id="id1">
<h2>Ridge<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>El modelo Ridge logra explicar aproximadamente el 68.2% (R² = 0.682) de la variabilidad de la variable objetivo. Esto indica un poder predictivo moderado, donde poco más de la mitad de los cambios en la variable dependiente pueden ser explicados por las variables independientes incluidas en el modelo.</p>
<p>En términos de error, el modelo comete, en promedio, un error de <span class="math notranslate nohighlight">\(4301 (MAE) en sus predicciones. El RMSE, que penaliza más los errores grandes, es de \)</span>6357. Esto sugiere que, si bien el error promedio es de alrededor de cinco mil unidades, existen algunas predicciones con errores considerablemente más grandes que elevan esta métrica.</p>
<p>El gráfico muestra que los puntos comienzan a dispersarse notablemente conforme los valores reales aumentan (especialmente después de las 60000 unidades). Esta dispersión más ancha confirma la existencia de errores de predicción mayores para valores altos. En conclusión el modelo presenta un desempeño aceptable pero con margen de mejora. Es útil para obtener una aproximación general, pero sus predicciones para valores altos, deben ser tomadas con cautela debido a su error considerable.</p>
</section>
<section id="id2">
<h2>Lasso<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>Se observa que el desempeño del modelo Lasso es casi idéntico al del modelo Ridge. Explica el 68.2% de la variabilidad de los datos, lo que representa una mejora insignificante de apenas 0.4 puntos porcentuales respecto al modelo Ridge.</p>
<p>Sus métricas de error son prácticamente iguales: un MAE de <span class="math notranslate nohighlight">\(4293 vs. \)</span>4301 de Ridge y un RMSE de <span class="math notranslate nohighlight">\(6358 vs. \)</span>6357.</p>
<p>El gráfico de dispersión para Lasso sería virtualmente indistinguible del de Ridge, mostrando el mismo patrón de dispersión y los mismos problemas para predecir valores altos con precisión. Se puede concluir que el modelo Lasso no ofrece una ventaja real sobre el modelo Ridge para este conjunto de datos en particular. Ambos modelos tienen el mismo poder explicativo y cometen errores de magnitud similar.</p>
</section>
<section id="evaluacion-final-del-modelo-de-clasificacion-en-el-conjunto-de-prueba">
<h2>Evaluación Final del Modelo de Clasificación en el Conjunto de Prueba<a class="headerlink" href="#evaluacion-final-del-modelo-de-clasificacion-en-el-conjunto-de-prueba" title="Permalink to this heading">#</a></h2>
<p>Para completar el análisis del objetivo de clasificación binaria, se evaluó el desempeño del mejor modelo de Regresión Logística identificado mediante <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> en el conjunto de prueba reservado para esta tarea. La evaluación de un modelo de clasificación requiere un análisis más multidimensional que la regresión, ya que es necesario considerar no solo la capacidad de predicción general (accuracy) sino también el equilibrio entre los diferentes tipos de error (falsos positivos y falsos negativos), lo cual es crucial dependiendo del contexto de aplicación.</p>
<p>El modelo se reentrenó con la totalidad del conjunto de entrenamiento de clasificación (<code class="docutils literal notranslate"><span class="pre">X_train_clf</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train_clf</span></code>) y se generaron tanto predicciones de clase (<code class="docutils literal notranslate"><span class="pre">predict</span></code>) como probabilidades (<code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>) para el conjunto de prueba. El desempeño se evaluó mediante un conjunto exhaustivo de métricas y visualizaciones:</p>
<ul class="simple">
<li><p><strong>Métricas de Evaluación</strong>:</p>
<ul>
<li><p><strong>Accuracy</strong>: Proporción general de predicciones correctas.</p></li>
<li><p><strong>Precision</strong>: Capacidad del modelo de no etiquetar como de alta demanda a un vehículo que no lo es (evitar falsos positivos).</p></li>
<li><p><strong>Recall</strong>: Capacidad del modelo de encontrar todos los vehículos de alta demanda (evitar falsos negativos).</p></li>
<li><p><strong>F1-score</strong>: Media armónica entre Precision y Recall, ideal para conjuntos balanceados.</p></li>
</ul>
</li>
<li><p><strong>Visualizaciones</strong>:</p>
<ul>
<li><p><strong>Matriz de Confusión</strong>: Muestra de forma explícita los aciertos (diagonal) y los errores (falsos positivos y falsos negativos) del modelo.</p></li>
<li><p><strong>Curva ROC y AUC</strong>: Evalúa la capacidad del modelo para distinguir entre clases a través de todos los posibles umbrales de clasificación. Un AUC de 0.5 representa un modelo aleatorio, mientras que 1.0 representa una separación perfecta.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred_clf</span> <span class="o">=</span> <span class="n">logreg_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_clf</span><span class="p">)</span>
<span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">logreg_cv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_clf</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_clf</span><span class="p">,</span> <span class="n">y_pred_clf</span><span class="p">)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test_clf</span><span class="p">,</span> <span class="n">y_pred_clf</span><span class="p">)</span>
<span class="n">rec</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_clf</span><span class="p">,</span> <span class="n">y_pred_clf</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_clf</span><span class="p">,</span> <span class="n">y_pred_clf</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluación Logistic Regression&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Precision:&quot;</span><span class="p">,</span> <span class="n">prec</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recall:&quot;</span><span class="p">,</span> <span class="n">rec</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F1-score:&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_clf</span><span class="p">,</span> <span class="n">y_pred_clf</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Baja Demanda&quot;</span><span class="p">,</span><span class="s2">&quot;Alta Demanda&quot;</span><span class="p">],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Baja Demanda&quot;</span><span class="p">,</span><span class="s2">&quot;Alta Demanda&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de confusión&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test_clf</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;r--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curva ROC&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Evaluación Logistic Regression
Accuracy: 0.8542997377798696
Precision: 0.8604332327940774
Recall: 0.8452525252525253
F1-score: 0.8527753244106258
</pre></div>
</div>
<img alt="_images/c61232fa71bbc6ce3f1df9cb064d3d300d8c450bfd17664c49d090445d9aec0d.png" src="_images/c61232fa71bbc6ce3f1df9cb064d3d300d8c450bfd17664c49d090445d9aec0d.png" />
<img alt="_images/edff2161906b1906dfd8c71a06767dd1f324f771709e4e40a40ff2f85bf76418.png" src="_images/edff2161906b1906dfd8c71a06767dd1f324f771709e4e40a40ff2f85bf76418.png" />
</div>
</div>
<section id="id3">
<h3>Regresión logística<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>El modelo de Regresión Logística muestra un desempeño sobresaliente en la clasificación de la demanda, con valores altos y balanceados en precisión, recall y F1-score, además de un AUC de 0.93 que confirma su fuerte capacidad de discriminación.</p>
<p>En términos prácticos, el modelo es confiable tanto para identificar correctamente la alta demanda como para evitar sobreestimaciones, lo cual lo hace útil en contextos de planificación de recursos o gestión operativa. Los errores (falsos positivos y falsos negativos) existen, pero están en proporciones manejables frente al número total de aciertos.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="intromini.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Información del Dataset</p>
      </div>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Modelos Ridge, Lasso y LogisticRegression</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#importar-librerias">Importar Librerías</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#lectura-de-datos">Lectura de Datos</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tratamiento-de-outliers-en-variables-numericas">Tratamiento de outliers en variables numéricas</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#price">Price</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#odometer">Odometer</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#valores-nulos">Valores Nulos</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocesamiento">Preprocesamiento</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminacion-de-variables">Eliminación de Variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminacion-de-observaciones-con-valores-faltantes-na">Eliminación de Observaciones con Valores Faltantes (NA)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#valores-unicos">Valores únicos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creacion-de-la-variable-binaria-highdemand">Creación de la Variable Binaria “HighDemand”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#separacion-de-los-conjutos-x-y-reg-y-clf">Separación de los conjutos X, y_reg, y_clf</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-correlacion-no-parametrica-para-variables-numericas-spearman">Análisis de Correlación No Paramétrica para Variables Numéricas (Spearman)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#agrupamiento-de-variables-categoricas-de-alta-cardinalidad">Agrupamiento de Variables Categóricas de Alta Cardinalidad</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preservacion-selectiva-de-modelos-por-frecuencia">Preservación Selectiva de Modelos por Frecuencia</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-relevancia-de-variables-categoricas-prueba-de-kruskal-wallis">Análisis de Relevancia de Variables Categóricas (Prueba de Kruskal-Wallis)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#seleccion-de-variables-basada-en-relevancia-predictiva-y-manejo-de-categoricas">Selección de Variables Basada en Relevancia Predictiva y Manejo de Categoricas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuracion-de-la-busqueda-de-hiperparametros-con-gridsearchcv">Configuración de la Búsqueda de Hiperparámetros con GridSearchCV</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepocesamiento-variables-categoricas-y-numericas">Prepocesamiento variables categóricas y numéricas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creacion-de-conjuntos-de-entrenamiento-y-prueba">Creación de Conjuntos de Entrenamiento y Prueba</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejecucion-de-la-busqueda-de-hiperparametros-y-entrenamiento-de-los-modelos">Ejecución de la Búsqueda de Hiperparámetros y Entrenamiento de los Modelos</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge">Ridge</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">Lasso</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-logistica">Regresión Logística</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-los-resultados-de-la-busqueda-de-hiperparametros">Análisis de los Resultados de la Búsqueda de Hiperparámetros</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion-de-desempeno">Evaluación de desempeño</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Ridge</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Lasso</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion-final-del-modelo-de-clasificacion-en-el-conjunto-de-prueba">Evaluación Final del Modelo de Clasificación en el Conjunto de Prueba</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Regresión logística</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Cristian Linero, David Marquez
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>